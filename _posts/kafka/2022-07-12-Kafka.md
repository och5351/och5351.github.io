---
title: "Kafka 란"
# header:
#   image: /assets/images/hadoop/hadoop_logo.svg
#   caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
layout: posts
categories:
  - Kafka
tags:
  - Kafka
  - Ingetion
toc: true
toc_sticky: true

date: 2022-07-12
last_modified_at: 2022-07-12
---


아파치 카프카는 아파치 소프트웨어 재단이 스칼라로 개발한 오픈 소스 메시지 브로커 프로젝트이다. 이 프로젝트는 실시간 데이터 피드를 관리하기 위해 통일된, 높은 처리량, 낮은 지연시간을 지닌 플랫폼을 제공하는 것이 목표를 가지는 프로젝트.

<br><br>

# Kafka 탄생
<br>

초기 운영 시에는 단방향 통신을 통해 소스 어플리케이션에서 타겟 어플리케이션으로 연동하는 소스코드를 작성했고 아키텍처가 복잡하지 않아서 운영이 힘들지 않았다.

시간이 지날수록 아키텍처는 거대해졌고 소스/타겟 어플리케이션의 개수가 점점 많아지면서 문제가 생겼다. 파이프라인 개수가 많아지면서 소스코드 및 버전 관리에서 이슈가 생겼으며, 타겟에 장애가 생길 경우 소스에 그대로 전달 됐다. 

파편화 된 데이터 파이프라인은 서비스를 안정적으로 운영하기 힘들어 이를 해결하기 위해 링크드인 데이터팀에서 기존의 상용 데이터 프레임워크와 오픈소스를 아키텍처에 녹여내어 데이터 파이프라인의 파편화를 개선하려고 했으며, 이 결과물이 아파치 카프카이다.

<br>

> KIP(Kafka Improvement Propsal) : KIP는 카프카의 주요 변경사항을 제안하는 방법 중 하나이다. KIP는 누구든 생성할 수 있으며 제안하게 된 사유, 변경사항, 신규/변경된 인터페이스에 대한 설명, 마이그레이션 계획 및 호환성에 대한 상세한 설명이 포함되어 있으면 된다.

> http://bit.lt/3aKK2FF

<br><br>

# Kafka 역할, 특징
<br>

실시간으로 저장하는 데이터의 양은 최소 테라바이트 단위를 넘어서 엑사바이트를 웃돈다. 이를 빅데이터라고 부르며, 적재되는 데이터의 종류는 다양하다.

- 스키마(Schema) 기반의 정형 데이터
- 일정한 규격이나 형태를 지니지 않은 비정형 데이터(그림, 영상, 음성 등)

수십 테라바이트를 넘어서는 방대한 양의 데이터를 기존의 데이터베이스로 관리하는 것은 불가능에 가깝기 때문에 데이터 레이크로 모든 데이터를 모은다.

<br>

데이터 레이크는 데이터 웨어하우스와 다르게 필터링 되거나 패키지화 되지 않은 데이터가 저장된다는 점이 특징이다. 즉, 운영되는 서비스로부터 수집 가능한 모든 데이터를 모으는 것.

웹, 앱 백엔드 서버, DB에서 발생하는 데이터를 데이터레이크에 직접 end-to-end 방식으로 넣으면 서비스하는 어플리케이션 개수가 많아졌을 때 파편화나 복잡도가 올라가는 문제가 발생한다. 그래서 ETL, 데이터 파이프라인을 구축해야 한다. 이 때 데이터 파이프라인을 안정적이고 확장성 높게 운영하기 위해 아파치 카프카를 활용한다.

<br>

1. 높은 처리량
   - 카프카는 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 브로커로부터 데이터를 받을 때 모두 묶어서 전송한다. 
   - 많은 양의 데이터를 송수신할 때 맺어지는 네트워크 비용은 무시할 수 없다. 동일한 양의 데이터를 보낼 때 네트워크 통신 횟수를 최소한으로 줄인다면 동일 시간 내에 더 많은 데이터를 전송할 수 있다.
   - 많은 양의 데이터를 묶은 단위로 처리하는 배치로 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그데이터를 처리하는 데에 적합하다.
   - 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리할 수 있다.
   - 파티션 개수만큼 컨슈머 개수를 늘려서 동일 시간 당 데이터 처리량을 늘린다.

2. 확장성
   - 카프카는 가변적인 환경(데이터가 갑자기 많이 들어오는 경우)에서 안정적으로 확장가능하도록 설계되었다. 데이터가 적을 때는 카프카 클러스터의 브로커를 최소한의 개수로 운영하다가 많아지면 클러스터의 브로커 개수를 자연스럽게 늘려 scale-out 할 수 있다. 반대의 경우 scale-in 할 수 있다.
   - scale-out, scale-in 기능은 클러스터의 무중단 운영을 지원한다.

3. 영속성
   - 데이터를 생성한 프로그램이 종료되더라도 사라지지 않은 데이터의 특성을 뜻한다. 카프카는 전송받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장한다.
   - 파일 시스템에 데이터를 적재하고 사용하면 느릴 수도 있다고 생각할 수 있지만 운영체제에서는 파일 I/O 성능 향상을 위해 페이지 캐시(page cache) 영역을 메모리에 따로 생성하여 사용한다. 페이지 캐시 메모리 영역을 사용하여 한 번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식이기 때문에 카프카가 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량이 높다.
   - 디스크 기반의 파일 시스템을 활용한 덕분에 브로커 어플리케이션이 장애 발생으로 인해 급작스럽게 종료되더라도 프로세스를 재시작하여 안전하게 데이터 처리를 할 수 있다.

4. 고가용성
   - 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다. 클러스터로 이루어진 카프카는 데이터 복제를 통해 고가용성의 특징을 가지게 된다. (여러 브로커 브로커에 데이터 저장)
   - 한 브로커에 장애가 발생하더라도 복제된 데이터가 나머지 브로커에 저장되어 있으므로 데이터 처리가 가능.

> min.insync.replicas 옵션을 사용하여(2로 지정) 최소 2개 이상의 브로커에 데이터가 완전히 복제됨을 보장한다. 

<br><br>
