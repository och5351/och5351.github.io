---
title: "Spark 배포"
toc: true
# header:
#   image: /assets/images/nifi/nifi_logo.svg
#   caption: "Photo credit: [**Wikipedia**](https://upload.wikimedia.org/wikipedia/commons/f/ff/Apache-nifi-logo.svg)"
layout: posts
categories:
  - Spark
tags:
  - Spark
  - Trouble Shooting
toc: true
toc_sticky: true

date: 2022-08-16
last_modified_at: 2022-08-16

---

<br><br>

# 1. 로컬 모드

<br>

로컬 모드는 모든 스파크 프로세스가 단일 시스템에서 실행되도록 하며, 로컬 시스템의 코어 수를 임의로 선택해 사용한다. 로컬 모드를 사용하는 것은 종종 새로 설치된 스파크를 테스트하는 빠른 방법이며, 작은 데이터세트에 대해 스파크 루틴을 신속하게 테스트 할 수 있다.

```sh
$SPARK_HOME/bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master local \
$SPARK_HOME/examples/jars/spark-examples*.jar 10
```

로컬 모드에서 사용할 코어 수는 local 명령문 뒤 괄호 안에 숫자로 나타낸다. 예를 들어, 2개의 코어를 사용하려면 local[2]; 로 표기하고, 시스템의 모든 코어를 사요하려면 local[*]; 로 표기한다.

로컬 모드에서 스파크를 실행할 때 로컬 시스템에 적절한 구성과 라이브러리를 사용할 수 있다면 로컬 파일 시스템의 모든 데이터와 HDFS, S3 또는 기타 파일 시스템의 데이터에 액세스할 수 있다.

로컬 모드를 사용하면 빠르게 시작하고 실행할 수 있지만, 프로덕션 유스케이스의 확장 및 효과 측면에서는 제한적이다.

<br><br>

# 2. 스파크 독립실행형

<br>

스파크 독립실행형은 내장형 또는 '독립실행형' 스케줄러를 나타낸다.

`독립실행형(Standalone)`이라는 용어는 말 그대로 클러스터 토폴로지와 아무 관련이 없다. 완전히 분산된 다중 노드 클러스터에서 독립실행형 모드로 스파크를 배포할 수 있는데, 이 경우 독립실행형은 외부 스케줄러가 필요 없다는 것을 뜻한다.

다중 호스트 프로세스 또는 서비스는 스파크 독립실행형 클러스터에서 실행되며, 각 서비스는 클러스터에서 실행 중인 지정된 스파크 응용 프로그램의 계획, 조정 및 관리에 중요한 역할을 한다.

URI 스키마로 스파크를 지정해 지정된 호스트 및 포트와 함게 응용 프로그램을 스파크 독립실행형 클러스터에 제출할 수 있다. 여기서 지정된 호스트 및 포트에서는 스파크 마스터 프로세스가 실행 중이다.

```sh
$SPARK_HOME/bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://mysparkmaster:7077 \
$SPARK_HOME/examples/jars/spark-examples*.jar 10
```

스파크 독립실행형을 사용하면 종속성이나 환경에 대한 깊은 고민 없이 빠르게 시작하고 실행할 수 있다. 각 스파크 릴리즈에는 스파크 독립실행형 클러스터에서 호스트가 지정된 역할을 맡을 수 있게 하는 바이너리 및 구성 파일을 비롯해 시작하는 데 필요한 모든 것이 포함돼 있다.

<br><br>

# 3. YARN에서의 스파크

<br>

스파크의 가장 일반적인 배포 방법은 하둡과 함께 제공되는 YARN 리소스 관리 프레임워크를 사용하는 것이다. YARN은 하둡 클러스터에서 워크로드를 예약하고 관리할 수 있는 하둡의 핵심 구성 요소다.

데이터브릭스의 연례 조사에 따르면 YARN과 독립실행형은 거의 같고 메소스는 그보다 뒤에 있다. <a href='https://databricks.com/resources/type/infographic-surveys'>[참조]</a>

하둡 에코시스템의 일급 객체(first-class citizens) 답게 스파크 응용 프로그램은 최소한의 노력으로 제출하고 관리를 쉽게 할 수 있다. 드라이버, 마스터, 실행자와 같은 스파크 프로세스는 리소스 매니저, 노드 매니저, 어플리케이션 마스터와 같이 YARN 프로세스에 의해 호스팅 되거나 촉진된다.

spark-submit, pyspark, spark-shell 프로그램에는 스파크 응용 프로그램을 YARN 클러스터에 제출하는 데 사용되는 커맨드 라인 인수가 포함된다.

```sh
$SPARK_HOME/bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode cluster \
$SPARK_HOME/examples/jars/spark-examples*.jar 10
```

YARN 을 스케줄러로 사용할 때 cluster 와 client라는 2개의 클러스터 배포 모드가 있다.

<br><br>

# 4. 메소스에서의 스파크

<br>

아파치 메소스는 버클리 캘리포니아 대학에서 개발한 오픈소스 클러스터 매니저로, 스파크의 생성을 포함한 리니지의 일부를 공유한다. 또한, 여러 유형의 응용 프로그램을 스케줄링할 수 있ㄷ으며, 클러스터의 활용도를 높이기 위해 세분화된 리소스 공유 기능을 제공한다.

```sh
$SPARK_HOME/bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master mesos://mesosdispatcher:7077 \
--deploy-mode cluster \
--supervies \
--executor-memory 20G \
--total-executor-cores 100 \
$SPARK_HOME/examples/jars/spark-examples*.jar 1000
```

메소스는 document를 참조한다.<a href='http://mesos.apache.org'>[참조]</a>

<br><br>
