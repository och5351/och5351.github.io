---
title: "데이터 흐름"
header:
  image: /assets/images/hadoop/hadoop_logo.svg
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
layout: posts
categories:
  - Hadoop
tags:
  - Hadoop
  - CLI
toc: true
toc_sticky: true

date: 2022-05-02
last_modified_at: 2022-05-02
---

<a id="home1"></a>
<br><br>

# 파일 읽기 상세

<br>

클라이언트가 HDFS, Namenode, Datanode 와 어떻게 상호작용하는지 데이터 흐름 관점에서 이해하기 위해 파일읽기 이벤트의 기본 순서



<br><br>

# 기본적인 파일시스템 연산

<br>

파일 시스템을 사용할 준비가 되면 파일 읽기, 디렉터리 생성, 파일 이동, 데이터 삭제, 디렉터리 목록 출력과 같은 일반적인 파일시스템 연산을 모두 수행할 수 있따. hadoop fs -help 명령을 실행하면 자세한 도움말 얻을 수 있다.

<br>

* 로컬 파일시스템의 파일 하나를 HDFS로 복사

   ```bash
   hadoop fs -copyFromLoacl input/docs/qunagle.txt \
   hdfs://localhost/user/tom/quangle.txt

   # 하둡 파일시스템의 쉘 명령어인 fs를 호출.
   # 로컬 호스트에서 실행되는 HDFS 인스턴스의 /user/tom/quangle.txt 로 복사된다.
   # URI의 schem 과 host를 생략하면 core-site.xml dp tjfwjdehls rlqhsrkqtdls hdfs://localhost를 가져온다.
   ```

* 절대 경로 대신 상대 경로 사용

   ```bash
   hadoop fs -copyFromLocal input/docs/quangle.txt /user/tom/quangle.txt
   # HDFS 홈 디렉터리는 /user/tom
   hadoop fs -copyFromLocal input/docs/quangle.txt quangle.txt
   # 같음
   ```

* HDFS에 복사 했던 파일을 다시 로컬 파일시스템에 가져오기

   ```bash
   hadoop fs -copyToLoacl quangle.txt quangle.copy.txt
   md5 input/docs/quangle.txt quangle.copy txt
   # MD5 (input/docs/quangle.txt) = e7891a2627cf263a079fb0f18256ffb2
   # MD5 (quangle.copy.txt) = e7891a2627cf263a079fb0f18256ffb2
   ```

> MD5 : MD5는 128비트 암호화 해시 함수이다. RFC 1321로 지정되어 있으며, 주로 프로그램이나 파일이 원본 그대로인지를 확인하는 무결성 검사 등에 사용된다. 1991년에 로널드 라이베스트가 예전에 쓰이던 MD4를 대체하기 위해 고안했다.

* 디렉터리 만들기

   ```bash
   hadoop fs -mkdir books
   hadoop fs -ls .
   # Found 2 items
   # drwxr-xr-x   -  tom   supergroup     0   2014-10-04 13:22 books
   # -rw-r--r--   1  tom   supergroup   119   2014-10-04 13:21 quangle.txt

   # 첫 번째 열 : 파일의 모드
   # 두 번째 열 : 전통적인 유닉스 파일시스템에는 없는 파일의 복제 계수(기본 복제 1)
   #              디렉터리는 데이터노드에는 저장되지 않고 네임노드에만 저장되고 메타데이터로 관리되므로 복제의 개념은 없다.(디렉터리의 경우 공란)
   # 3, 4번째 열 : 파일의 소유자와 그룹
   # 5 번째 열 : 바이트 단위의 파일 크기(디렉터리는 0)
   # 6, 7번째 열 : 마지막으로 수정된 날짜와 시간
   # 8 번째 열 : 파일 또는 디렉터리의 절대 경로로 표시된 이름
   ```

> HDFS는 POSIX 처럼 파일과 디렉터리에 대한 권한 모델을 가지고있다.(r,w,x)

> POSIX : POSIX는 이식 가능 운영 체제 인터페이스의 약자로, 서로 다른 UNIX OS의 공통 API를 정리하여 이식성이 높은 유닉스 응용 프로그램을 개발하기 위한 목적으로 IEEE가 책정한 애플리케이션 인터페이스 규격이다.

> HDFS는 POSIX와 달리 파일의 실행을 지원하지 않는다.

> 각 파일과 디렉터리는 소유자(owner), 그룹(group), 모드(mode)를 가진다.

> 하둡은 기본적으로 보안이 비활성화된 상태로 실행된다.(클라이언트의 사용자 계정을 인증하지 않음)

> 권한 검사가 가능하도록 설정되면 클라이언트의 사용자 이름이 소유자와 일치할 때 소유자 권한으로 체크되고, 클라이언트가 그룹의 멤버와 일치할 때 그룹 권한이 체크되고, 일치하지 않는다면 그 밖의 사용자 권한이 체크된다.(dfs.permissions.enabled 속성의 기본값)

> 네임노드 프로세스의 식별자인 슈퍼유저 개념도 있으며 권한 검사를 수행하지 않는다.

<br>

# 하둡 파일시스템 자바 구현

> 하둡 파일시스템

<div align='center'>
<table>
    <thead>
        <tr>
            <th colspan="1">파일 시스템</th>
            <th colspan="1">URI 스킴</th>
            <th colspan="1">자바 구현체(org.apache.hadoop 아래)</th>
            <th colspan="1">설명</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Local</td>
            <td>file</td>
            <td>fs.LocalFileSystem</td>
            <td>클라이언트 측의 체크섬을 사용하는 로컬 디스크를 위한 파일시스템. 체크섬을 사용하지 않는 로컬 파일시스템은 RawLocalFileSystem 사용</td>
        </tr>
        <tr>
            <td>HDFS</td>
            <td>hdfs</td>
            <td>hdfs.DistributedFileSystem</td>
            <td>하둡 분산 파일시스템. HDFS는 맵리듀스와 효율적으로 연동하기 위해 설계됨.</td>
        </tr>
        <tr>
            <td>WebHDFS</td>
            <td>webhdfs</td>
            <td>hdfs.web.WebHdfsFileSystem</td>
            <td>HTTP를 통해 HDFS에 인증을 통한 읽기/쓰기를 제공하는 파일시스템</td>
        </tr>
        <tr>
            <td>Secure<br>WebHDFS</td>
            <td>swebhdfs</td>
            <td>hdfs.web.SWebHdfsFileSystem</td>
            <td>webHDFS의 HTTPS버전</td>
        </tr>
        <tr>
            <td>HAR</td>
            <td>har</td>
            <td>fs.HarFileSystem</td>
            <td>아카이브 파일을 휘한 파일시스템. 하둡 아카이브는 네임노드의 메모리 욜량을 줄이기 위해 HDFS 수 많은 파일을 묶어놓은 파일이다. HAR 파일을 생성하려면 hadoop archive 명령어를 실행하면 된다.</td>
        </tr>
        <tr>
            <td>View</td>
            <td>viewfs</td>
            <td>viewfs.ViewFileSystem</td>
            <td>다른 하둡 파일시스템을 위한 클라이언트 측 마운트 테이블. 페더레이션 네임노드의 마운트 지점을 생성할 때 주로 사용</td>
        </tr>
        <tr>
            <td>FTP</td>
            <td>ftp</td>
            <td>fs.ftp.FTPFileSystem</td>
            <td>FTP 서버를 지원하는 파일시스템</td>
        </tr>
        <tr>
            <td>S3</td>
            <td>s3a</td>
            <td>fs.s3a.S3AFileSystem</td>
            <td>아마존 S3를 지원하는 파일시스템. 구버전의s3n(S3 네이티브) 구현체를 대체함</td>
        </tr>
        <tr>
            <td>Azure</td>
            <td>wasb</td>
            <td>fs.azure.NativeAzureFileSystem</td>
            <td>마이크로소프트의 애저를 지원하는 파일시스템</td>
        </tr>
        <tr>
            <td>Swift</td>
            <td>swift</td>
            <td>fs.swift.snative.SwiftNativeFileSystem</td>
            <td>오픈스택 스위프트를 지원하는 파일시스템</td>
        </tr>
    </tbody>
</table>
</div>

<br>

하둡은 다양한 파일시스템을 위한 인터페이스를 제공하는데, 접근할 파일시스템의 인스턴스를 선택할 때 일반적으로 URI 스킴을 사용한다.

```bash
hadoop fs -ls file:///
```

<br>

# HTTP

파일시스템 인터페이스를 Java API로만 제공하면 자바로 작성되지 않은 어플리케이션으로 HDFS에 접근하는 것은 어렵게 된다. WebHDFS 프로토콜을 이용한 HTTP REST API를 사용하면 다른 언어도 HDFS에 쉽게 접근할 수 있다. 그러나<b><u> HTTP 인터페이스는 네이티브 자바 클라이언트보다는 느리므로 매우 큰 파일을 전송할 때는 주의해야 한다.</u></b>

<br>

HTTP로 HDFS에 접근하는 방법은 두 가지가 있다.

- HTTP 요청을 HDFS 데몬이 직접 처리하는 방식
- 클라이언트 대신 DistributedFileSystem API로 HDFS에 접근하는 프록시를 경유하는 방식

위 두 가지 방식 모두 WebHDFS 프로토콜을 이용한다.

<br>

<div align='center'>
<img src='https://user-images.githubusercontent.com/45858414/165306811-dbc567bb-bf65-4611-a5fd-54ac0df86b52.png' width='70%' heigth='70%' />
</div>


<br>

HDFS 데몬이 HTTP 요청을 직접 처리하는 방식은 네임노드와 데이터노드에 내장된 웹 서버가 WebHDFS의 말단으로 작용한다. WebHDFS의 활성화 여부는 dfs.webhdfs.enabled 속성에 정의하며 기본값은 true 다. 파일에 대한 메타데이터 연산은 네임노드가 처리하지만, 파일을 읽고 쓰는 연산은 먼저 네임노드로 전달되고, 네임노드는 파일 데이터를 스트리밍할 데이터노드를 알려주는 HTTP 리다이렉트를 클라이언트에 보낸다.

<br>

DistributedFileSystem API로 HDFS에 접근하는 프록시를 경유하는 방식은 하나 또는 그 이상의 독립(standalone) 프록시 서버를 통하는 것이다. 프록시 서버는 상태를 저장할 필요가 없으므로 표준 로드 밸런서를 사용해도 괜찮다. 클러스터의 모든 트래픽은 프록시를 경유하므로 클라이언트는 네임노드와 데이터노드에 직접 접근할 필요가 없다. 프록시를 통하면 엄격한 방화벽이나 대역폭 제한 정책을 적용하기 쉽다. <b><u>프록시를 통한 방식은 서로 다른 데이터 센터에 있는 하둡 클러스터 사이의 데이터 전송이나 외부 네트워크에 있는 클라우드에서 운영되는 하둡 클러스텡 접근할 때 일반적으로 이용되는 방법이다.</u><b>

<br>

# C

하둡은 자바 FileSystem 인터페이스를 모방한 libhdfs라는 C 라이브러리를 제공한다. 모든 HDFS(로컬 파일시스템 S3 등) 에 접근할 수 있다. libhdfs는 자바 파일시스템 클라이언트를 호출하기 위해 자바 네이티브 인터페이스(JNI)를 사용한다. WebHDFS 인터페이스를 위해 libwebhdfs 라이브러리도 제공하고 있다.

<br>

C API는 자바 API와 매우 비슷하지만, 보통 자바 API보다 한 발 늦게 개발되므로 최신 기능을 지원하지 않을 수도 있다. hdfs.h 헤더 파일은 아파치 하둡 바이너리 타르볼 배포판의 include 디렉터리에서 찾을 수 잇다. 아파치 하둡 바이너리 타르볼 배포판은 64비트 리눅스를 위한 libhdfs 바이너리를 포함하고 있지만, 다른 플랫폼에서 사용하려면 소스 트리 최상단의 BUILDING.txt 문서의 지시에 다라 직접 빌드해야 한다.

# NFS

하둡의 NFSv3 게이트웨이를 이용하면 로컬 클라이언트 파일시스템에 HDFS를 마운트할 수 있다. 또한 파일시스템을 다루는 ls나 cat 같은 Unix 유틸리티를 이용할 수 있으며, 파일 업로드 및 일반적인 프로그래밍 언어에서 파일시스템을 다루는 POSIX 라이브러리도 사용할 수 있다. HDFS는 파일의 끝에만 쓰기를 허용하므로 파일에 추가하는 작업이 가능은 하지만 파일의 임의 위치에 있는 데이터를 수정하는 것은 지원하지 않는다. HDFS 마운트를 지원하는 가장 안정적인 솔루션이다.

# FUSE

퓨즈는 Filesystem in Userspace(사용자 공간에서의 파일시스템)로, 사용자 공간과 유닉스 파일시스템을 통합한 파일시스템을 지원한다. 하둡의 Fuse-DFS contrib 모듈은 표준 로컬 파일시스템에 HDFS(또는 모든 하둡 파일시스템)를 마운트할 수 있는 기능을 제공한다. Fuse-DFS는 C로 작성된 libhdfs로 HDFS 인터페이스를 구현했다. 