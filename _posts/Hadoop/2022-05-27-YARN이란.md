---
title: "YARN 이란"
# header:
#   image: /assets/images/hadoop/hadoop_logo.svg
#   caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
layout: posts
categories:
  - Hadoop
tags:
  - Hadoop
  - YARN
toc: true
toc_sticky: true

date: 2022-05-27
last_modified_at: 2022-05-27
---

<br>

Apache YARN(Yet Another Resource Negotiator)은 하둡의 클러스터 자원 관리 시스템이다. YARN은 맵리듀스의 성능을 높이기 위해 하둡 2에서 처음 도입되었다. 하지만 YARN은 맵리듀스뿐만 아니라 다른 분산 컴퓨팅 도구도 지원한다.

YARN은 클러스터의 자원을 요청하고 사용하기 위한 API를 제공한다. 하지만 사용자 코드에서 직접 이러한 API를 사용할 수는 없다. 대신 사용자는 YARN 이 내장된 분산 컴퓨팅 프레임워크에서 고수준 API를 작성해야 하며, 따라서 사용자는 자원 관리의 자세한 내용은 알 수 없다. 전체적인 구조는 아래와 같다.

<br>
<div align='center'>
<img src='https://user-images.githubusercontent.com/45858414/170660479-06b1d1cb-f8f7-4712-8505-db847728a354.png' >
</div>
<br>

맵리듀스, 스파크 등과 같은 분산 컴퓨팅 프레임워크는 클러스터 계산 계층(YARN)과 클러스터 저장 계층(HDFS와 HBase) 위에서 YARN 애플리케이션을 실행한다. 프레임워크 기반의 애플리케이션 계층이 존재하는 것을 알 수 있으며 피그, 하이브, 크런치와 같은 애플리케이션은 맵리듀스, 스파크, 테즈에서 구동되는 처리 프레임워크의 예이며, YARN에 직접 접근하지는 않는다.

<br><br>

# YARN 애플리케이션 수행 해부

<br>

YARN은 리소스 매니저와 노드 매니저 등 두 가지 유형의 장기 실행 데몬을 통해 핵심 서비스를 제공한다. 클러스터에서 유일한 리소스 매니저는 클러스터 전체 자원의 사용량을 관리하고, 모든 머신에서 실행되는 노드 매니저는 컨테이너를 구동하고 모니터링하는 역할을 맡는다. 자원(메모리, CPU 등)의 사용 한도를 가진 특정 애플리케이션 프로세스는 컨테이너에서 실행된다. YARN의 설정 방법에 따라 다르지만, 컨테이너는 Unix 프로세스 또는 리눅스 cgroup이 된다. 

<br>
<div align='center'>
<img src='https://user-images.githubusercontent.com/45858414/170897326-c26d0792-4bf1-4ed3-a4fb-804a23332740.png' width='70%' />
</div>
<br>

1. 애플리케이션을 구동하기 위해 리소스 매니저에 접속 하여 애플리케이션 마스터 프로세스의 구동을 요청
2. 리소스 매니저는 컨테이너에서 애플리케이션 마스터를 시작할 수 있는 노드 매니저를 하나 찾는다. (2a, 2b), (애플리케이션 마스터가 딱 한 번만 실행될지는 애플리케이션에 따라 다르다.)
3. 애플리케이션 마스터가 단순한 계산을 단일 컨테이너에서 수행하고 그 결과를 클라이언트에 반환한 후 종료되거나, 리소스 매니저에 더 많은 컨테이너를 요청(3eksrP) 한 후 분산 처리를 수행(4a, 4b)

<br>

YARN 자체는 클라이언트, 마스터, 프로세스와 같은 애플리케이션이 서로 통신하는 기능은 제공하지 않는다. 대부분 주요 YARN 애플리케이션은 하둡의 RPC와 같은 원격 호출 방식을 이용하여 상태 변경을 전달하고 클라이언트로부터 결과를 받는데 구체적인 방법은 애플리케이션에 따라 다르다.

<br><br>

# 자원 요청

<br>

YARN은 유연한 자원 요청 모델을 갖고 있다. 다수의 컨테이너를 요청할 때는 각 컨테이너에 필요한 컴퓨터 자원(메모리, CPU)의 용량뿐만 아니라 해당 요청에 대한 컨테이너의 지역성 제약도 표현할 수 있다.

<b><u>분산 데이터 처리 알고리즘에서 클러스터의 네트워크 대역폭을 효율적으로 활용하기 위해서는 지역성을 보장하는 것이 가장 중요하다.</u></b> 따라서 YARN은 특정 애플리케이션이 호출한 컨테이너에 대한 지역성 제약을 규정하는 것을 허용한다. 지역성 제약은 특정 노드나 랙 또는 클러스터의 다른 곳(외부 랙)에서 컨테이너를 요청할 때 사용된다. 

가끔은 지역성 제약이 불가능할 때가 있는데, 이 때는 할당이 실패하거나 또는 선택적으로 제약을 조금 느슨하게 적용할 수 있다. 예를 들어 특정 노드를 요청했는데 그 노드에서 컨테이너를 시작할 수 없으면(현재 다른 컨테이너가 실행되고 있기 때문에) YARN은 동일한 랙의 다른 노드에서 컨테이너를 시작하려 시도한다. 또 다시 실패하면 클러스터의 임의 노드에서 다시 시도할 것이다.

YARN 애플리케이션은 실행 중에는 아무 때나 자원 요청을 할수 있다. 예를 들어 애플리케이션은 처음에 모든 요청을 하거나 유동적인 접근이 필요한 경우에는 애플리케이션의 요구에 따라 동적으로 자원을 추가로 요청할 수 있다.

전자의 방식을 따르는 스파크는 클러스터에서 고정 개수의 수행자(excutor)를 시작한다. 이와 달리 맵리듀는 두 단계로 되어 있다. 처음에 필요한 맵 태스크 컨테이너를 요청한다. 하지만 리듀스 태스크 컨테이너는 맵 태스크가 어느 정도 실행된 후에야 시작될 수 있다. 또한 특정 태스크가 실패하면 실패한 태스크를 다시 실행하기 위해 컨테이너를 추가로 요청한다.

<br><br>

# 애플리케이션의 수명

<br>

YARN 애플리케이션의 수명은 애플리케이션 마다 다르다. 실행 시간보다는 사용자가 실행하는 잡의 방식에 따라 애플리케이션을 분류 하는 것이 좋다. 

<br>

1. 사용자의 잡 당 하나의 애플리케이션이 실행 되는 방식(맵리듀스 잡)
2. 워크플로나 사용자의 잡 세션(잡은 서로 관련이 없을 수 있다.) 당 하나의 애플리케이션이 실행되는 방식(스파크)
3. 서로 다른 사용자들이 공유할 수 있는 장기 실행 어플리케이션. 일종의 코디네이션 역할 수행(아파치 슬라이더, 임팔라)

<br>

2번 째 유형이 1번 째 유형보다 훨씬 더 효율적이다. 순차적으로 실행되는 잡이 동일한 컨테이너를 재사용할 수 있기 때문이다. 또한 잡 사이에 공유 데이터를 캐싱할 수 있는 큰 장점도 있다. 
